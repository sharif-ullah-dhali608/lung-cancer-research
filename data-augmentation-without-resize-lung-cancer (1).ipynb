{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":13961031,"datasetId":8899454,"databundleVersionId":14734078}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Image Augmentation (No Resize) for Balancing Lung Cancer Classification Training Data**\n\nThis step focuses solely on augmenting the original Train dataset to address class imbalance without modifying the input image resolution. Ten different geometric and color transformations (including horizontal flip, vertical flip, rotation, shear, and zoom) are applied, ensuring each class is boosted to 1200 samples. The output zip file contains the augmented images in their original size, which will be used for Fine-Tuning the EfficientNet model in subsequent steps.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nimport shutil\nimport cv2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n\n# --- 1. Custom Preprocessing Function (CLAHE + Gamma) ---\ndef apply_clahe_and_gamma(img):\n    \"\"\"\n    Applies CLAHE and Gamma Correction (gamma=0.5) for contrast enhancement.\n    This function is designed to be passed to the ImageDataGenerator.\n    \n    IMPORTANT: The ImageDataGenerator expects the output to be in the \n    range [0, 255] (float or int) for subsequent rescaling.\n    \"\"\"\n    \n    # Ensure image is in the correct format (CV2 expects uint8 for processing)\n    img = img.astype(np.uint8)\n\n    # 1. CLAHE (Contrast Limited Adaptive Histogram Equalization)\n    if len(img.shape) == 3 and img.shape[2] == 3:\n        # --- COLOR IMAGE PROCESSING (L*a*b* space) ---\n        img_lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n        l, a, b = cv2.split(img_lab)\n        \n        # Apply CLAHE to L channel\n        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n        cl = clahe.apply(l)\n        \n        # Merge back and convert to RGB\n        limg = cv2.merge((cl, a, b))\n        img_clahe = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n    else:\n        # --- GRAYSCALE IMAGE PROCESSING ---\n        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n        img_clahe = clahe.apply(img)\n\n\n    # 2. Gamma Correction (gamma=0.5)\n    gamma = 0.5\n    inv_gamma = 1.0 / gamma\n    # Create lookup table\n    table = np.array([((i / 255.0) ** inv_gamma) * 255\n                      for i in np.arange(256)]).astype(\"uint8\")\n    \n    # Apply gamma correction\n    # Note: cv2.LUT takes the input image and the table, using the 'uint8' image\n    img_corrected = cv2.LUT(img_clahe, table)\n    \n    # Return the corrected image as float32 in [0, 255] range\n    return img_corrected.astype(np.float32)\n\n# --- Configuration & Path Setup ---\nBASE_INPUT_DIR = '/kaggle/input/without-augmentation-lung-cancer-dataset/Lung Cancer Dataset'\nTRAIN_DIR = os.path.join(BASE_INPUT_DIR, 'Train')\nTARGET_OUTPUT_DIR = '/kaggle/working/Augmented_Dataset_Enhanced/Train'\nTARGET_COUNT_PER_CLASS = 1200\nCLASS_NAMES = ['Bengin cases', 'Malignant cases', 'Normal cases']\n\nprint(\"Configuration and Path Setup complete.\")\n\n# --- 2. Create the Augmentation Generator (WITH Preprocessing and Normalization) ---\n\n# The steps for ImageDataGenerator are applied in this order:\n# 1. Random Augmentations (Rotation, Shift, Zoom, etc.)\n# 2. Custom Preprocessing Function (apply_clahe_and_gamma runs here)\n# 3. Rescaling/Normalization (rescale=1./255 runs last)\n\ndatagen = ImageDataGenerator(\n    # --- Normalization (Rescaling) ---\n    rescale=1./255,                 # Standard normalization: converts [0, 255] to [0.0, 1.0]\n    \n    # --- Custom Preprocessing ---\n    preprocessing_function=apply_clahe_and_gamma, # Apply CLAHE and Gamma Correction\n    \n    # --- Augmentation Parameters ---\n    rotation_range=25,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    zoom_range=[0.8, 1.2],\n    horizontal_flip=True,\n    vertical_flip=True,\n    brightness_range=[0.7, 1.3],\n    channel_shift_range=30.0,\n    fill_mode='nearest',\n)\nprint(\"Augmentation Generator with CLAHE/Gamma and Normalization created.\")\n\n# --- Data Augmentation Logic and Saving ---\nprint(\"üöÄ Starting Data Augmentation...\")\n\n# Create the target output directory structure\nos.makedirs(TARGET_OUTPUT_DIR, exist_ok=True)\n\n# Note on Saving: When using the generator's .flow() method with a preprocessing_function\n# and rescale, the saved images will reflect the full transformation (CLAHE/Gamma AND Normalization). \n# This is usually NOT desirable for saving, as you want to train your model on \n# normalized data, but save un-normalized images to view them easily.\n\n# Since the goal here is to save the FINAL (normalized) output ready for model consumption:\n\nfor class_name in CLASS_NAMES:\n    input_class_path = os.path.join(TRAIN_DIR, class_name)\n    output_class_path = os.path.join(TARGET_OUTPUT_DIR, class_name)\n    \n    os.makedirs(output_class_path, exist_ok=True)\n    \n    # Collect existing data files\n    image_files = [f for f in os.listdir(input_class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.webp'))]\n    current_count = len(image_files)\n    \n    print(f\"\\nüìÅ Class: {class_name} (Current Count: {current_count})\")\n\n    # 1. Copy existing data (We will skip this to only save the augmented/processed data)\n    # The generator will create the augmented/processed versions, so we only need to \n    # generate the NEEDED augmented data.\n\n    if current_count >= TARGET_COUNT_PER_CLASS:\n        print(f\"    Data count is sufficient. Skipping augmentation.\")\n        continue\n\n    # 2. Calculate needed augmentation\n    needed_augmentation = TARGET_COUNT_PER_CLASS - current_count\n    total_generated = 0\n    \n    # 3. Augment and Save (Looping through images until target is met)\n    for filename in image_files:\n        if total_generated >= needed_augmentation:\n            break\n            \n        img_path = os.path.join(input_class_path, filename)\n        \n        try:\n            # Load image WITHOUT specifying target_size to preserve original size\n            img = load_img(img_path)\n            x = img_to_array(img)\n            # Reshape: (1, height, width, channels)\n            x = x.reshape((1,) + x.shape) \n            \n            # Generate and save images (these saved images are NOW preprocessed and normalized)\n            for batch in datagen.flow(x, batch_size=1, \n                                      save_to_dir=output_class_path, \n                                      save_prefix=f'{class_name}_aug_{total_generated}', \n                                      save_format='png'):\n                total_generated += 1\n                \n                if total_generated >= needed_augmentation:\n                    break\n                    \n        except Exception as e:\n            print(f\"    ‚ö†Ô∏è Error processing file {filename}: {e}\")\n            \n    # IMPORTANT: Since we did not copy the original images, we must now calculate \n    # how many images we must generate to reach the target COUNT.\n    \n    # To simplify, we will just generate enough to cover the shortfall + originals.\n    \n    # Re-run the augmentation loop until the target is met (this ensures the target is hit)\n    while total_generated < needed_augmentation:\n        for filename in image_files:\n            if total_generated >= needed_augmentation:\n                break\n            \n            img_path = os.path.join(input_class_path, filename)\n            \n            try:\n                img = load_img(img_path)\n                x = img_to_array(img)\n                x = x.reshape((1,) + x.shape) \n                \n                for batch in datagen.flow(x, batch_size=1, \n                                          save_to_dir=output_class_path, \n                                          save_prefix=f'{class_name}_aug_{total_generated}', \n                                          save_format='png'):\n                    total_generated += 1\n                    if total_generated >= needed_augmentation:\n                        break\n                        \n            except Exception as e:\n                pass # Skip error handling for simplicity in the second loop\n\n    # Now we copy the originals and ensure we have enough total files\n    \n    # Copying originals is essential since the generator only creates *new* augmented images.\n    for img_file in image_files:\n        shutil.copy(os.path.join(input_class_path, img_file), output_class_path)\n    \n    total_final_count = len(os.listdir(output_class_path))\n    print(f\"    ‚úÖ New augmented data created: {total_generated} files. Total Data (Originals + Augmented): {total_final_count} files.\")\n\n\n# --- Zip the folder for download ---\nprint(\"\\nüì¶ Zipping the dataset...\")\n# Compress the entire Augmented_Dataset folder into a ZIP file\nshutil.make_archive('Augmented_Dataset_Enhanced', 'zip', '/kaggle/working/Augmented_Dataset_Enhanced')\nprint(\"    ‚≠ê Augmented dataset successfully created as 'Augmented_Dataset_Enhanced.zip'.\")\n\nprint(\"\\n--- Pipeline Complete ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:52:30.248306Z","iopub.execute_input":"2025-12-02T15:52:30.248538Z","iopub.status.idle":"2025-12-02T15:57:58.390650Z","shell.execute_reply.started":"2025-12-02T15:52:30.248518Z","shell.execute_reply":"2025-12-02T15:57:58.389957Z"}},"outputs":[{"name":"stderr","text":"2025-12-02 15:52:31.966578: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764690752.201968      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764690752.273076      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"Configuration and Path Setup complete.\nAugmentation Generator with CLAHE/Gamma and Normalization created.\nüöÄ Starting Data Augmentation...\n\nüìÅ Class: Bengin cases (Current Count: 100)\n    ‚úÖ New augmented data created: 1100 files. Total Data (Originals + Augmented): 1140 files.\n\nüìÅ Class: Malignant cases (Current Count: 1000)\n    ‚úÖ New augmented data created: 200 files. Total Data (Originals + Augmented): 1195 files.\n\nüìÅ Class: Normal cases (Current Count: 500)\n    ‚úÖ New augmented data created: 700 files. Total Data (Originals + Augmented): 1173 files.\n\nüì¶ Zipping the dataset...\n    ‚≠ê Augmented dataset successfully created as 'Augmented_Dataset_Enhanced.zip'.\n\n--- Pipeline Complete ---\n","output_type":"stream"}],"execution_count":1}]}